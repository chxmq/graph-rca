\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}
\usepackage{bm}
\usepackage{framed}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{orcidlink}

% Simple framed box environments compatible with IEEE class
\newenvironment{methodbox}{%
    \vspace{0.5em}%
    \begin{framed}
    \noindent\textbf{IMPORTANT METHODOLOGICAL NOTE}\\[0.5em]
}{%
    \end{framed}
    \vspace{0.5em}%
}

\newenvironment{limitbox}{%
    \vspace{0.5em}%
    \begin{framed}
    \noindent\textbf{LIMITATION: External Root Causes}\\[0.5em]
}{%
    \end{framed}
    \vspace{0.5em}%
}

\makeatletter
\AtBeginDocument{\DeclareMathVersion{bold}
\SetSymbolFont{operators}{bold}{T1}{times}{b}{n}
\SetSymbolFont{NewLetters}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathrm}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathit}{bold}{T1}{times}{b}{it}
\SetMathAlphabet{\mathbf}{bold}{T1}{times}{b}{n}
\SetMathAlphabet{\mathtt}{bold}{OT1}{pcr}{b}{n}
\SetSymbolFont{symbols}{bold}{OMS}{cmsy}{b}{n}
\renewcommand\boldmath{\@nomath\boldmath\mathversion{bold}}}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\doi{10.1109/ACCESS.2026.XXXXXXX}

\title{Temporal Correlation Heuristics for Automated Incident Triage: A Baseline System with LLMs and RAG}

\author{\uppercase{KrishnaTejaswi Shenthar}\,\orcidlink{0009-0008-5191-153X}\authorrefmark{1},
\uppercase{Yash Saraogi}\,\orcidlink{0009-0009-5005-2865}\authorrefmark{1},
\uppercase{Yash Gautam}\,\orcidlink{0009-0000-6292-6827}\authorrefmark{1}, and 
\uppercase{Mohana}\,\orcidlink{0000-0002-6642-2949}\authorrefmark{1}}

\address[1]{Department of Computer Science and Engineering, RV College of Engineering, Bangalore 560059, India}

\tfootnote{This work was supported by RV College of Engineering, Bangalore, India. The authors acknowledge the computational resources provided by the institution.}

\markboth
{Tejaswi \headeretal: Temporal Correlation Heuristics for Automated Incident Triage}
{Tejaswi \headeretal: Temporal Correlation Heuristics for Automated Incident Triage}

\corresp{Corresponding author: Mohana (e-mail: mohana@rvce.edu.in).}


\begin{abstract}
Contemporary cloud-native infrastructures face substantial operational challenges when analyzing system logs and managing incidents, as conventional pattern-matching techniques prove inadequate for handling diverse log structures and temporal event dependencies. We introduce GraphRCA, a baseline system architecture leveraging directed acyclic graphs (DAGs), large language models (LLMs), and retrieval-augmented generation (RAG) for automated incident triage. Our approach uses temporal ordering heuristics---explicitly distinguished from formal causal inference---to construct dependency graphs representing event correlations. Our baseline comprises three core components: (1) an LLM-driven log parsing mechanism requiring no predefined templates to extract structured data from heterogeneous sources, (2) a graph-theoretic algorithm constructing temporal dependency networks for correlation-based analysis, and (3) a knowledge-retrieval pipeline anchoring generated solutions in organizational documentation. The implementation operates entirely on-premises with locally-hosted language models, addressing data sovereignty requirements inherent to regulated industries. Comprehensive empirical evaluation on LogHub datasets (BGL and HDFS, 2000 entries each) with statistical rigor (3 runs per configuration) demonstrates \textbf{99.6\%} field-level parsing accuracy on BGL and \textbf{99.2\%} on HDFS without template engineering. Root cause candidate identification achieves \textbf{77.8\%} accuracy across 200 diverse failure scenarios spanning 6 categories (600 total tests), with Security and Management categories achieving effectively higher precision. DAG construction exhibits O(n) linear complexity, completing in under 20ms for 2000 log entries. Batch inference optimization achieves \textbf{5.7$\times$ throughput improvement} (0.40 $\rightarrow$ 2.27 logs/s at batch size 32), significantly reducing the performance gap with traditional parsers. We explicitly position this as a baseline using temporal ordering heuristics rather than formal causal inference, providing a reproducible benchmark for future research incorporating Granger causality, transfer entropy, or learned causal discovery methods. We release GraphRCA as an open-source baseline with standardized evaluation methodology, enabling the research community to benchmark future advances in causal inference, multi-modal fusion, and domain-specific enhancements for end-to-end log-based incident analysis.
\end{abstract}

\begin{keywords}
AIOps, directed acyclic graphs, incident management, large language models, log analysis, retrieval augmented generation, root cause analysis, vector databases
\end{keywords}

\titlepgskip=-21pt

\maketitle

\section{Introduction}
\label{sec:introduction}
\PARstart{C}{ontemporary} software ecosystems built on microservices and distributed computing paradigms present significant operational complexity, with individual deployments routinely producing multi-terabyte log volumes per day. System failures within these environments typically propagate through service dependencies, manifesting as cascading degradations rather than isolated events \cite{he2021survey}. Current incident response methodologies depend extensively on human expertise from Site Reliability Engineering teams, establishing performance constraints that adversely affect mean time to resolution (MTTR) metrics essential for service availability commitments.

\subsection{Motivation and Problem Statement}
Contemporary log analysis methodologies face several fundamental constraints:

\textbf{Structural Diversity:} Production environments integrate heterogeneous technology stacks---spanning relational databases, application servers, message brokers, and edge services---each producing logs adhering to vendor-specific or custom formats. Conventional parsing relies on manually-engineered pattern matchers (regex), demanding continuous maintenance as log schemas evolve and introducing fragility.

\textbf{Event Interdependencies:} System anomalies seldom occur in isolation; instead, originating faults propagate temporally through architectural dependencies. For instance, connection pool saturation may induce timeout cascades, triggering defensive mechanisms like circuit breakers. Accurate root cause candidate identification necessitates modeling these temporal correlations, though we acknowledge that temporal precedence indicates correlation rather than formal causation.

\textbf{Expertise Distribution:} Successful remediation requires synthesizing knowledge across system topology, historical failure patterns, and procedural runbooks. This expertise remains fragmented across technical documentation, institutional memory, and individual practitioners---creating accessibility barriers during time-critical incidents.

\textbf{Volume Scalability:} As microservice architectures expand (commonly hundreds of services), aggregate log generation reaches millions of entries daily. Human-driven analysis becomes computationally infeasible at these scales.

\begin{methodbox}
Our temporal dependency model uses correlation heuristics rather than formal causality. Temporal precedence ($t_i < t_j$) indicates correlation but not necessarily causation. We provide this as a reproducible baseline against which future causal inference methods can be compared. Our evaluation is valid only for scenarios where the root cause candidate appears in logs and is the earliest event.
\end{methodbox}

\subsection{Research Contributions}
We present GraphRCA, a unified system architecture synthesizing graph-theoretic modeling, neural language processing, and knowledge-base retrieval to address the aforementioned challenges. Our baseline contributions comprise:

\begin{enumerate}
\item \textbf{Schema-Agnostic Log Parsing via LLMs:} We develop a parsing methodology exploiting pre-trained language models' semantic comprehension to extract structured fields from arbitrary log formats, eliminating template engineering requirements (detailed in Section IV-A).

\item \textbf{Temporal Correlation Modeling:} We formulate algorithms constructing directed acyclic graphs encoding event chronology and temporal correlations, facilitating root cause candidate identification through graph traversal (Section IV-B). We explicitly distinguish correlation from causation and position this as a baseline for future work incorporating formal causal inference methods.

\item \textbf{Documentation-Anchored Solution Generation:} We implement a retrieval-augmented approach where remediation guidance is synthesized by language models conditioned on retrieved institutional knowledge, constraining factual drift (Section IV-C).

\item \textbf{Data-Sovereign Deployment Model:} We architect the system for on-premises execution with self-hosted language models, satisfying data residency mandates for regulated sectors (Section V).

\item \textbf{Empirical Assessment Methodology:} We establish evaluation protocols encompassing accuracy metrics, latency profiling, and component ablation (Section VI).

\item \textbf{Reproducible Reference Implementation:} We provide complete source code with containerized orchestration enabling deployment replication.
\end{enumerate}

\textbf{Baseline Positioning:} We position GraphRCA as a reproducible baseline rather than a definitive solution. Our temporal dependency model represents a simple heuristic that future work can improve upon with formal causal inference methods (Granger causality, transfer entropy, learned causal discovery). We release our implementation, evaluation scenarios, and benchmark datasets to enable direct comparison and accelerate progress in end-to-end AIOps research. This baseline establishes standardized metrics and evaluation protocols against which more sophisticated approaches can be measured.

\subsection{Paper Organization}
Section II surveys related work in log analysis, AIOps, and LLM applications. Section III presents the system architecture. Section IV details our methodology including algorithms and design decisions. Section V describes implementation specifics. Section VI presents experimental evaluation framework. Section VII discusses findings, limitations, and deployment considerations. Section VIII concludes with future directions.

\section{Related Work}

\subsection{Traditional Log Analysis}
Established log processing methodologies predominantly employ rule-based extraction coupled with statistical outlier identification. The \textbf{Drain} system \cite{he2020loghub} constructs fixed-depth parsing trees enabling real-time operation, though necessitating hyperparameter optimization. \textbf{Spell} \cite{du2016spell} leverages longest common subsequence algorithms for template inference, yet exhibits sensitivity to format heterogeneity.

Anomaly detection techniques including \textbf{principal component analysis} \cite{xu2009detecting} and \textbf{clustering-based approaches} \cite{lin2016log} successfully flag behavioral deviations from baseline patterns. However, these methods provide limited causal insight---a fundamental requirement for actionable incident resolution.

\subsection{Deep Learning for Log Analysis}
\textbf{DeepLog} \cite{du2017deeplog} introduced recurrent neural architectures (LSTM) for sequence modeling of execution traces, establishing neural approaches for anomaly identification. The methodology demonstrates effective pattern recognition yet demands extensive labeled datasets and offers constrained causal explanatory power.

\textbf{LogRobust} \cite{zhang2019robust} employs distributed semantic representations for format-invariant parsing, exhibiting superior resilience to schema variations compared to template-driven methods. Nevertheless, its scope remains confined to log structuring rather than comprehensive incident diagnosis.

\textbf{LogAnomaly} \cite{meng2019loganomaly} synthesizes template mining with self-attention mechanisms for unsupervised deviation detection. While circumventing annotation requirements represents an advantage, the approach terminates at anomaly flagging without progressing to remediation synthesis.

\subsection{AIOps Platforms}
Artificial Intelligence for IT Operations (AIOps) represents an emerging operational paradigm \cite{dang2019aiops}. Enterprise solutions including Moogsoft and BigPanda implement event correlation and alert consolidation mechanisms, mitigating notification overload. These platforms concentrate predominantly on incident aggregation workflows rather than explicating causal pathways or generating remediation procedures.

\textbf{CloudRanger} \cite{chen2021cloudrangerpipeline} contributes a cloud-optimized triage architecture yet maintains dependency on static procedural documentation, precluding adaptive knowledge synthesis.

\subsection{LLMs in System Operations}
Contemporary investigations examine large language model applicability to operational workflows. \textbf{OpsEval} \cite{chen2023opseval} establishes performance benchmarks for LLM-driven operational question-answering, revealing capability potential alongside consistency limitations.

\textbf{LogPrompt} \cite{jiang2023logprompt} demonstrates prompt-based techniques for schema-independent log extraction. Our research advances this foundation by unifying parsing with graph-based correlation analysis and knowledge-conditioned response generation.

\subsection{Retrieval-Augmented Generation}
Retrieval-augmented approaches \cite{lewis2020retrieval} mitigate generative model hallucination through document-conditioned inference. Systems including \textbf{REALM} and \textbf{DPR} validate efficacy for knowledge-intensive question answering. Subsequent developments incorporate \textbf{self-reflection mechanisms} \cite{asai2023selfrag} enhancing output fidelity, alongside \textbf{active retrieval strategies} \cite{jiang2023active} optimizing document selection. Systematic evaluations \cite{yu2024evaluation, gao2023retrieval} assess RAG performance across application domains. Context-aware retrieval \cite{ram2023context} and memory-augmented architectures \cite{cheng2023lift} represent further architectural refinements.

The \textbf{CYGENT} system \cite{balasubramanian2024cygent} operationalizes RAG for security log synopsis generation via GPT-3, establishing viability within operational contexts. However, its scope terminates at summarization rather than progressing to diagnostic causality and prescriptive remediation. We adapt retrieval augmentation specifically for incident resolution, where institutional documentation grounds solution synthesis while on-premises deployment preserves data sovereignty.

\textbf{Research Gap:} Prior research treats constituent challenges---log structuring, anomaly flagging, model evaluation---in isolation. No existing framework delivers integrated end-to-end automation spanning log acquisition through actionable solution delivery. GraphRCA distinctively synthesizes schema-free parsing, graph-theoretic correlation modeling, and documentation-anchored generation within a data-sovereign architecture.

\textbf{Baseline Contribution:} GraphRCA provides a reproducible reference implementation integrating LLM-based log parsing, temporal dependency modeling, and retrieval-augmented solution generation. We provide this implementation as a reproducible baseline against which future work can compare more sophisticated causal inference methods, multi-modal fusion approaches, and domain-specific enhancements. Our evaluation framework, including 20 failure scenarios across 6 categories and field-level parsing metrics on LogHub datasets, establishes a standardized methodology for benchmarking integrated AIOps systems.

\section{System Architecture}
\label{sec:architecture}
\subsection{Architectural Overview}
GraphRCA employs a modular pipeline architecture (Figure \ref{fig:architecture}) designed for extensibility and fault tolerance. The system processes log files through five stages: parsing, DAG construction, context extraction, retrieval, and solution synthesis. Each component is independently deployable, enabling horizontal scaling of bottleneck stages.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig1.png}
\caption{GraphRCA System Architecture showing data flow through parsing, DAG construction, and RAG-based solution generation with integrated storage backends.}
\label{fig:architecture}
\end{figure}

\subsection{Core Components}

\subsubsection{Log Ingestion Layer}
Accepts log files in various formats (.log, .txt, .json) with preprocessing for timestamp normalization and encoding detection. Implements buffering for large files and stream processing capabilities for real-time analysis.

\subsubsection{LLM-Based Parser}
Utilizes locally-deployed language models (Llama 3.2 3B, Qwen 2.5-Coder) for structured information extraction. Unlike template-based parsers, this approach leverages the model's semantic understanding to extract fields without format-specific rules. Employs Pydantic schemas for output validation, ensuring type safety.

\subsubsection{DAG Generator}
Constructs directed acyclic graphs representing temporal dependencies between log entries. The optimized algorithm achieves $O(n)$ linear complexity through sequential temporal ordering, completing in under 20ms for 2,000 entries.

\subsubsection{Context Builder}
Traverses the DAG to extract correlation chains and identify root cause candidates. Implements depth-first search with cycle detection (ensuring DAG property) and configurable traversal strategies (breadth-first for shallow analysis, depth-first for deep correlation analysis).

\subsubsection{RAG Engine}
Integrates vector-based document retrieval with LLM generation. ChromaDB stores embedded documentation chunks (nomic-embed-text, 768-dim vectors) enabling semantic similarity search. Retrieved context grounds generation, reducing factual errors.

\subsection{Storage Infrastructure}

\textbf{ChromaDB (Vector Store):} Manages embedded documentation with HNSW indexing for sub-linear search complexity. Supports metadata filtering and hybrid search capabilities.

\textbf{MongoDB (Document Store):} Persists DAG structures and analysis contexts with flexible schema accommodating evolving log formats. Provides temporal queries for historical incident analysis.

\textbf{Ollama Service:} Deploys quantized LLMs locally, eliminating API latency and data exfiltration risks. Supports GPU acceleration (CUDA) for throughput optimization.

\subsection{Deployment Architecture}
Docker Compose orchestrates multi-container deployment with:
\begin{itemize}
\item Service isolation and dependency management
\item Persistent volumes for data durability
\item Network policies for security
\item GPU resource allocation for LLM inference
\item Health monitoring and automatic restarts
\end{itemize}

The architecture scales horizontally by replicating parser and RAG components behind load balancers, while databases employ sharding for high-throughput scenarios.


\section{Methodology}
\label{sec:methodology}

\subsection{Template-Free Log Parsing}

\subsubsection{Problem Formulation}
Given a raw log entry $l \in \mathcal{L}$, extract structured information $s = (t, m, v, f_1, \ldots, f_k)$ where $t$ is timestamp, $m$ is message, $v$ is severity level, and $f_i$ are optional fields (PID, component, trace ID, etc.). Traditional approaches define extraction rules $r_i$ manually:

\begin{equation}
s = \bigcup_{i=1}^{n} r_i(l)
\end{equation}

Our LLM-based approach learns a mapping $\phi: \mathcal{L} \rightarrow \mathcal{S}$ implicitly through pre-training:

\begin{equation}
s = \phi(l | \text{schema}, \text{examples})
\end{equation}

\subsubsection{Structured Output Generation}
We define a Pydantic schema $\mathcal{S}$:

\begin{algorithm}[t]
\caption{LLM-Based Log Parsing}
\label{alg:parsing}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Raw log entry $l$, Schema $\mathcal{S}$, LLM $\mathcal{M}$
\STATE \textbf{Output:} Structured log entry $s$
\STATE $prompt \leftarrow$ ConstructPrompt($l$, $\mathcal{S}$)
\STATE $response \leftarrow \mathcal{M}$.generate($prompt$, format=JSON)
\STATE $s \leftarrow$ ValidateSchema($response$, $\mathcal{S}$)
\IF{$s$ is invalid}
    \STATE $s \leftarrow$ RetryWithCorrection($l$, $\mathcal{S}$, $response$)
\ENDIF
\RETURN $s$
\end{algorithmic}
\end{algorithm}

Figure \ref{fig:log_parsing_example} illustrates the transformation from raw log text to structured JSON output, demonstrating the LLM's ability to extract typed fields without predefined templates.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig8_log_parsing_example.png}
\caption{LLM-based log parsing: Raw log entry transformed to structured JSON with color-coded field extraction (timestamp, level, component, message). No templates required; 99.6\% accuracy with Pydantic schema validation.}
\label{fig:log_parsing_example}
\end{figure}


The prompt engineering strategy employs few-shot learning:

\begin{equation}
P = \text{task\_desc} \oplus \text{schema\_spec} \oplus \text{examples} \oplus l
\end{equation}

where $\oplus$ denotes concatenation. Low temperature ($T=0.2$) sampling prioritizes factual extraction over creative generation.

\subsubsection{Optimization Strategies}
\textbf{Batch Processing:} Group similar log entries for parallel inference, reducing overhead. Our empirical evaluation demonstrates significant throughput improvements through batched inference (Table \ref{tab:batching}).

\begin{table}[t]
\centering
\caption{Batch Inference Performance Comparison}
\label{tab:batching}
\begin{tabular}{lcccc}
\toprule
\textbf{Batch} & \multicolumn{2}{c}{\textbf{Quadro GV100}} & \multicolumn{2}{c}{\textbf{A100-40GB}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Size} & \textbf{Throughput} & \textbf{Latency} & \textbf{Throughput} & \textbf{Latency} \\
\midrule
1 & 0.40 logs/s & 2,515 ms & 1.90 logs/s & 527 ms \\
8 & 0.48 logs/s & 2,069 ms & 2.66 logs/s & 376 ms \\
16 & 0.82 logs/s & 1,224 ms & 4.67 logs/s & 214 ms \\
32 & 2.27 logs/s & 441 ms & \textbf{12.18 logs/s} & \textbf{82 ms} \\
\midrule
\textbf{Speedup} & \multicolumn{2}{c}{5.7$\times$ (batch 1$\rightarrow$32)} & \multicolumn{2}{c}{6.4$\times$ (batch 1$\rightarrow$32)} \\
\bottomrule
\end{tabular}
\end{table}

Batching multiple log entries in a single LLM prompt amortizes the per-request overhead. On Quadro GV100 (workstation-class), we achieve \textbf{5.7$\times$ throughput improvement} at batch size 32 (0.40 $\rightarrow$ 2.27 logs/s). On datacenter-grade A100-40GB, the system scales to \textbf{12.18 logs/s} with 82ms latency---a \textbf{5.4$\times$ improvement} over Quadro at identical batch sizes, demonstrating production viability. Figure \ref{fig:throughput} visualizes this performance scaling.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig10_throughput.png}
\caption{Batch inference throughput and latency. Larger batch sizes amortize per-request overhead, achieving 5.7$\times$ speedup on Quadro GV100.}
\label{fig:throughput}
\end{figure}


\textbf{Caching:} Hash-based memoization for identical entries, common in repeated error logs.

\textbf{Adaptive Retry:} If validation fails, inject error feedback into the prompt for correction.

\subsection{Temporal Correlation Modeling}
\label{sec:methodology_correlation}

\textbf{METHODOLOGICAL NOTE:} Our approach uses temporal ordering as a correlation heuristic rather than formal causal inference. We explicitly distinguish correlation from causation and position this as a baseline for future work incorporating Granger causality \cite{granger1969}, transfer entropy \cite{schreiber2000}, or learned causal discovery methods.

We present a baseline temporal dependency model for correlation-based analysis. Our approach uses temporal ordering as a simple heuristic for identifying correlated events, acknowledging that this represents a simplification suitable for establishing a reproducible baseline. Future work can improve upon this with formal causal inference methods (Granger causality, transfer entropy, learned causal discovery).

\subsubsection{Graph Construction}
Given a temporally-ordered log chain $L = \{l_1, l_2, \ldots, l_n\}$ where $t(l_i) < t(l_{i+1})$, we construct a DAG $G = (V, E)$ using sequential temporal ordering:

\begin{algorithm}[t]
\caption{DAG Construction Algorithm (O(n) Sequential)}
\label{alg:dag}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Ordered log chain $L = \{l_1, \ldots, l_n\}$
\STATE \textbf{Output:} DAG $G = (V, E)$, root $r$, leaves $\mathcal{L}$
\STATE Initialize $V \leftarrow \{v_i | l_i \in L\}$, $E \leftarrow \emptyset$
\STATE Sort $V$ by timestamp: $t(v_1) < t(v_2) < \ldots < t(v_n)$
\FOR{$i = 1$ to $n-1$}
    \STATE $E \leftarrow E \cup \{(v_i, v_{i+1})\}$ \COMMENT{Sequential edge}
    \STATE $v_{i+1}.parent \leftarrow v_i$
    \STATE $v_i.children \leftarrow v_i.children \cup \{v_{i+1}\}$
\ENDFOR
\STATE $r \leftarrow v_1$ \COMMENT{First node = root}
\STATE $\mathcal{L} \leftarrow \{v_n\}$ \COMMENT{Last node = leaf}
\RETURN $G, r, \mathcal{L}$
\end{algorithmic}
\end{algorithm}

\textbf{Complexity:} This algorithm achieves $O(n)$ linear time complexity by establishing sequential parent-child relationships based on temporal ordering, avoiding the $O(n^2)$ all-pairs comparison of naive approaches.

The \texttt{Correlate} predicate currently implements temporal ordering but can be enhanced with:
\begin{itemize}
\item Component matching (errors in same service)
\item Trace ID correlation (distributed tracing)
\item Semantic similarity (error messages referencing same resources)
\end{itemize}

where $\texttt{Correlate}(l_i, l_j)$ is a correlation predicate that currently implements:
\begin{itemize}
\item \textbf{Temporal precedence}: $t(l_i) < t(l_j)$ (necessary but not sufficient for causation)
\item \textbf{Component matching}: Events within same service component
\item \textbf{Trace correlation}: Shared distributed trace IDs
\item \textbf{Semantic similarity}: Error messages referencing same resources
\end{itemize}

\subsubsection{Limitations of Temporal Correlation}
\textbf{LIMITATION: Spurious Correlations}

Temporal ordering ($t(l_i) < t(l_j)$) indicates correlation but not necessarily causation. Two events occurring sequentially may be:
\begin{itemize}
\item \textbf{Correlated but independent:} Events may occur in sequence due to scheduled tasks, periodic operations, or shared external triggers without direct causal relationship.
\item \textbf{Effects of a common cause:} Multiple events may be consequences of an external trigger (e.g., network failure) not captured in logs, creating spurious temporal dependencies.
\item \textbf{Logging artifacts:} Timing differences in log emission may not reflect actual execution order, particularly in distributed systems with clock skew.
\end{itemize}

This means our DAG may contain spurious edges between temporally correlated but causally independent events. For example, a user login at $t_1$ followed by a database query at $t_2$ creates edge $(v_1, v_2)$ even if they are independent operations.

Future work will incorporate formal causality methods (Granger causality, transfer entropy, do-calculus) to reduce spurious relationships and improve accuracy.

\subsubsection{Root Cause Candidate Identification}
We identify the \textit{root cause candidate} as the earliest event in the DAG with no incoming edges:

\begin{equation}
\rho = \arg\min_{v \in V} t(v) \quad \text{s.t.} \quad \text{parent}(v) = \emptyset
\end{equation}

\begin{limitbox}
Equation (3) assumes the root cause appears as the earliest logged event. This assumption fails when:
\begin{itemize}
\item \textbf{External triggers}: True cause is external to the system (infrastructure failure, configuration change)
\item \textbf{Logging gaps}: Logs begin mid-incident, after root cause occurred
\item \textbf{Silent failures}: Some failures don't generate log entries until they cascade
\item \textbf{Multiple entry points}: In distributed systems, first logged event may be symptom rather than cause
\end{itemize}
Our evaluation (Section~\ref{sec:evaluation}) is valid only for scenarios where the root cause IS present in logs and is the earliest event.
\end{limitbox}

For scenarios with multiple roots (parallel failures), we rank by severity:

\begin{equation}
\rho^* = \arg\max_{v \in R} \text{severity}(v)
\end{equation}

where $R = \{v \in V | \text{parent}(v) = \emptyset\}$.

\subsubsection{Correlation Chain Extraction}
Extract the sequence of events from root to leaves via DFS:

\begin{algorithm}[t]
\caption{Correlation Chain Extraction}
\label{alg:chain}
\begin{algorithmic}[1]
\STATE \textbf{Input:} DAG $G$, root node $r$
\STATE \textbf{Output:} Correlation chain $C$
\STATE $C \leftarrow []$
\STATE \textbf{function} DFS($v$)
\STATE \hspace{0.5cm} $C$.append($v$.message)
\STATE \hspace{0.5cm} \textbf{for each} $u \in v$.children \textbf{do}
\STATE \hspace{1cm} DFS($u$)
\STATE \hspace{0.5cm} \textbf{end for}
\STATE \textbf{end function}
\STATE DFS($r$)
\RETURN $C$
\end{algorithmic}
\end{algorithm}

\subsection{Retrieval-Augmented Generation}
Figure \ref{fig:rag_pipeline} illustrates the complete RAG pipeline from query construction to grounded solution generation.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig6_rag_pipeline.png}
\caption{Retrieval-Augmented Generation pipeline: Root cause and context are embedded, matched against ChromaDB vector store via cosine similarity, and top-k documents ground the LLM solution synthesis.}
\label{fig:rag_pipeline}
\end{figure}


\subsubsection{Documentation Embedding}
Documentation $D = \{d_1, \ldots, d_m\}$ is chunked and embedded:

\begin{equation}
D' = \text{Chunk}(D, \text{size}=1000, \text{overlap}=200)
\end{equation}

\begin{equation}
\mathcal{E} = \{\mathbf{e}_i | \mathbf{e}_i = \text{Embed}(d'_i), d'_i \in D'\}
\end{equation}

Using nomic-embed-text: $\mathbf{e}_i \in \mathbb{R}^{768}$.

\subsubsection{Semantic Retrieval}
Query construction combines root cause and context:

\begin{equation}
q = \rho \oplus "\text{Context: }" \oplus \text{Join}(C, "\backslash n")
\end{equation}

Retrieve top-$k$ documents by cosine similarity:

\begin{equation}
\text{TopK} = \arg\max_{d_i \in D'} \frac{\mathbf{e}_q \cdot \mathbf{e}_i}{||\mathbf{e}_q|| \cdot ||\mathbf{e}_i||}
\end{equation}

Approximate nearest neighbor search (HNSW) reduces complexity from $O(m)$ to $O(\log m)$.

\subsubsection{Solution Synthesis}
The final prompt combines retrieved context:

\begin{equation}
P_{\text{final}} = \text{instruction} \oplus \rho \oplus C \oplus \text{TopK} \oplus \text{format\_spec}
\end{equation}

LLM generates structured solution $\sigma$:

\begin{equation}
\sigma = \mathcal{M}(P_{\text{final}}, T=0.1)
\end{equation}

Low temperature ensures deterministic, factual responses.

\subsection{Quality Assurance and Optimization}

\textbf{Validation Pipeline:} Multi-stage validation ensures output quality:
\begin{enumerate}
\item Schema validation (Pydantic)
\item Temporal consistency (timestamps ordered)
\item DAG acyclicity (topological sort)
\item Retrieval relevance (minimum similarity threshold)
\end{enumerate}

\textbf{Error Handling:} Graceful degradation with fallback mechanisms:
\begin{itemize}
\item LLM timeout $\rightarrow$ retry with cached prompt
\item Parsing failure $\rightarrow$ regex fallback for critical fields
\item Empty retrieval $\rightarrow$ general troubleshooting template
\end{itemize}

\textbf{Performance Optimizations:}
\begin{itemize}
\item Session-based caching (content hash)
\item Batch embedding generation
\item Connection pooling for databases
\item Asynchronous I/O for non-blocking operations
\end{itemize}

\section{Implementation}
\label{sec:implementation}

\subsection{Technology Stack}
\textbf{Core Framework:} Python 3.10 with type hints and async/await support.

\textbf{LLM Integration:} 
\begin{itemize}
\item Ollama for local inference with JSON output format
\item Pydantic schemas for structured output validation
\item Temperature control ($T=0.2$) for deterministic extraction
\end{itemize}

\textbf{Vector Database:}
\begin{itemize}
\item ChromaDB with HTTP client
\item HNSW indexing for efficient search
\item Metadata filtering support
\end{itemize}

\textbf{Document Store:}
\begin{itemize}
\item MongoDB 6.0 with change streams
\item Compound indexes on timestamps
\item Aggregation pipeline for analytics
\end{itemize}

\textbf{Text Processing:}
\begin{itemize}
\item LangChain RecursiveCharacterTextSplitter
\item Unicode normalization (NFKC)
\item Regex-based sanitization
\end{itemize}

\subsection{Model Configuration}

\textbf{Llama 3.2 (3B):}
\begin{itemize}
\item Context window: 8192 tokens
\item Quantization: 4-bit (GPTQ)
\item Inference: approximately 1-3 seconds per entry
\item Memory: 4-6 GB GPU VRAM
\end{itemize}

\textbf{Qwen 2.5-Coder (3B):}
\begin{itemize}
\item Specialized for technical logs
\item Better code snippet handling
\item Inference: approximately 1-3 seconds per entry
\end{itemize}

\textbf{Nomic-Embed-Text:}
\begin{itemize}
\item Dimension: 768
\item Max sequence: 8192 tokens
\item Batch size: 32 for throughput
\end{itemize}

\subsection{Deployment Configuration}

Docker Compose specification:
\begin{itemize}
\item \textbf{ChromaDB:} 2 CPU cores, 4GB RAM, persistent volume
\item \textbf{MongoDB:} 2 CPU cores, 8GB RAM, replica set
\item \textbf{Ollama:} 4 CPU cores, 16GB RAM, 1 GPU
\item \textbf{Network:} Bridge with service discovery
\end{itemize}

\subsection{Data Models}
Strongly-typed Pydantic models ensure type safety:

\texttt{LogEntry}: timestamp, message, level, optional fields (11 total)

\texttt{DAGNode}: id, parent\_id, children[], log\_entry

\texttt{DAG}: nodes[], root\_id, leaf\_ids[], root\_cause

\texttt{Context}: root\_cause, correlation\_chain[]

\texttt{SolutionQuery}: context, query, response, sources[]

\subsection{Reproducibility}
To facilitate reproducibility and extension, we provide:
\begin{itemize}
\item \textbf{Source Code:} Complete Python implementation with type annotations
\item \textbf{Containerization:} Docker Compose configuration for single-command deployment
\item \textbf{Sample Data:} Synthetic log scenarios and documentation corpus
\item \textbf{Configuration:} Environment files with all hyperparameters
\item \textbf{Scripts:} Evaluation scripts for metric computation
\end{itemize}

\textbf{Hardware Requirements:}
\begin{itemize}
\item Minimum: 8GB RAM, 4 CPU cores (CPU-only inference)
\item Recommended: 16GB RAM, GPU with 8GB+ VRAM (accelerated inference)
\end{itemize}

\textbf{Deployment Time:} Initial setup requires approximately 10-15 minutes for container builds and model downloads. Subsequent startups complete in under 60 seconds.

\section{Experimental Evaluation}
\label{sec:evaluation}

\subsection{Experimental Setup}

\subsubsection{Hardware Configuration}
\textbf{Primary Platform (Baseline):}
\begin{itemize}
\item \textbf{CPU:} Intel Xeon (Lenovo ThinkStation P920)
\item \textbf{GPU:} NVIDIA Quadro GV100 (32GB HBM2, 870 GB/s bandwidth)
\item \textbf{RAM:} 64GB DDR4 ECC
\item \textbf{Storage:} NVMe SSD
\end{itemize}

\textbf{Scalability Validation Platform:}
\begin{itemize}
\item \textbf{GPU:} NVIDIA A100-PCIE-40GB (40GB HBM2e, 1,555 GB/s bandwidth)
\end{itemize}

Results on A100 demonstrate \textbf{5.4$\times$ throughput improvement} over Quadro GV100 at identical batch sizes (Table \ref{tab:batching}), confirming linear scalability to datacenter-grade infrastructure.


\subsubsection{Software Environment}
\begin{itemize}
\item OS: Ubuntu 22.04 LTS
\item Docker: 24.0+
\item Python: 3.13
\item CUDA: 12.8
\end{itemize}

\subsection{Dataset Description}

\subsubsection{Synthetic Dataset}
LogGenerator module creates realistic failure scenarios:

\textbf{Scenario 1---Database Degradation:}
\begin{itemize}
\item Root: Connection pool exhaustion
\item Effects: Query timeouts, service degradation
\item Logs: Generated entries showing progression
\end{itemize}

\textbf{Scenario 2---Security Breach:}
\begin{itemize}
\item Root: Brute force authentication
\item Effects: Account lockouts, rate limiting
\item Logs: Generated security event sequence
\end{itemize}

\textbf{Scenario 3---Memory Leak:}
\begin{itemize}
\item Root: Resource exhaustion
\item Effects: OOM errors, process crashes
\item Logs: Generated resource monitoring events
\end{itemize}

\textbf{Dataset Statistics:}
\begin{itemize}
\item Total scenarios: 3 (database degradation, security breach, memory leak)
\item Total log entries: 10 per scenario (30 total)
\item Avg entries/scenario: 10
\item Temporal span: 5-10 minutes per scenario
\end{itemize}

\subsubsection{Real-World Dataset}
Flask application logs exhibiting:
\begin{itemize}
\item Startup sequences
\item Request/response patterns
\item Database connection failures
\item Rate limiting events
\item API timeout errors
\item Health check cycles
\end{itemize}

\subsubsection{Public Benchmark Datasets}
For baseline comparison and reproducibility, we evaluate on two LogHub datasets \cite{he2021survey}:

\textbf{BGL (Blue Gene/L):}
\begin{itemize}
\item \textbf{Source:} Supercomputer logs from Lawrence Livermore National Laboratory
\item \textbf{Size:} 2,000 log entries (BGL\_2k subset)
\item \textbf{Content:} System events including kernel messages, hardware errors, and operational logs
\end{itemize}

\textbf{HDFS (Hadoop Distributed File System):}
\begin{itemize}
\item \textbf{Source:} Distributed storage system logs
\item \textbf{Size:} 2,000 log entries (HDFS\_2k subset)
\item \textbf{Content:} Block operations, replication events, and storage management logs
\end{itemize}

Both datasets provide diverse log formats for evaluating parsing generalization and enable direct comparison with the Drain baseline parser.

\subsection{Documentation Corpus}
The effectiveness of the RAG component is fundamentally dependent on the quality, coverage, and relevance of the underlying documentation corpus. This section describes the documentation used in our evaluation.

\subsubsection{Corpus Composition}
Our evaluation corpus consists of curated real-world incident postmortems:
\begin{itemize}
\item \textbf{Curated incidents:} 200 manually annotated production incidents from 50+ companies including GitHub, Cloudflare, AWS, Google, Microsoft, Datadog, Roblox, and others.
\item \textbf{Incident categories:} Database, Software, Network, Infrastructure, Security, Hardware failures spanning 2009--2024.
\item \textbf{Per-incident documentation:} Each incident includes \texttt{postmortem.md} (human-readable summary), \texttt{ground\_truth.json} (labeled root cause), and \texttt{logs.txt} (synthetic log evidence).
\item \textbf{Total corpus:} 200 incident postmortems, approximately 50,000 tokens.
\end{itemize}

\textbf{Raw Source Documents:} Additionally, we collected 192 raw postmortems from GitHub repositories and SRE Weekly archives. These serve as distractor documents for retrieval noise sensitivity analysis.

\subsubsection{Corpus Characteristics}
\begin{itemize}
\item \textbf{Average document length:} approximately 250 tokens per postmortem
\item \textbf{Chunking strategy:} RecursiveCharacterTextSplitter with 1000-token chunks and 200-token overlap
\item \textbf{Vector dimension:} 768 (nomic-embed-text)
\end{itemize}

\subsubsection{Known Documentation Gaps}
The corpus has limitations affecting solution quality:
\begin{itemize}
\item \textbf{Postmortem focus:} Documentation describes ``what happened'' rather than ``how to fix it''---operational runbooks would improve solution actionability
\item \textbf{Technology bias:} Heavy representation of web services (GitHub, Cloudflare) may limit generalization to other domains (embedded systems, IoT)
\end{itemize}

These gaps directly impact RAG performance: scenarios without relevant documentation produce generic or incomplete solutions. We acknowledge this dependency as a fundamental limitation of the RAG approach, where solution quality is bounded by documentation quality and coverage.

\subsubsection{Documentation Dependency Analysis}
To quantify the impact of documentation quality, we conduct an ablation study (Section VI-E) comparing:
\begin{itemize}
\item RAG with full documentation corpus (200 incidents)
\item RAG with partial corpus (50\% randomly removed)
\item RAG with no documentation (direct LLM generation)
\end{itemize}

Results demonstrate that solution quality degrades significantly when relevant documentation is absent, validating the critical importance of corpus curation for production deployment.

\subsection{Ground Truth Annotation}
To validate our system's performance, we require ground truth labels for root cause identification and solution quality assessment. This section describes our annotation methodology.

\subsubsection{Synthetic Dataset Ground Truth}
For synthetic scenarios generated by the LogGenerator module:
\begin{itemize}
\item \textbf{Ground truth creation:} Each scenario is designed with a known root cause specified during generation. The root cause is explicitly encoded in the scenario definition (e.g., ``Connection pool exhaustion'' for database degradation scenarios).
\item \textbf{Validation:} Generated logs are manually verified to ensure the root cause appears as the earliest event in the log sequence, matching the scenario specification.
\item \textbf{Coverage:} 3 synthetic scenarios with known root causes, 30 total log entries.
\end{itemize}

\subsubsection{Evaluation Approach}
Due to resource constraints typical of academic research, we employ automated validation rather than multi-annotator human evaluation:
\begin{itemize}
\item \textbf{Automated verification:} DAG construction correctness is verified programmatically through acyclicity checks and temporal consistency validation.
\item \textbf{Root cause validation:} For synthetic scenarios, predicted root causes are compared against known ground truth.
\item \textbf{Qualitative assessment:} Generated solutions are manually reviewed by the authors for relevance and actionability.
\end{itemize}

\textbf{Limitation:} This evaluation approach lacks the rigor of multi-annotator studies with inter-rater reliability metrics. Future work should include independent expert evaluation with formal agreement measures.

\subsection{Evaluation Metrics}

\subsubsection{Parsing Metrics}
\textbf{Field Accuracy:}
\begin{equation}
A_f = \frac{\text{\# correctly extracted fields}}{\text{\# total fields}} \times 100\%
\end{equation}

\textbf{Coverage:}
\begin{equation}
C_f = \frac{\text{\# logs with field present}}{\text{\# total logs}} \times 100\%
\end{equation}

\subsubsection{DAG Metrics}
\textbf{Acyclicity:} Verified via topological sort existence.

\textbf{Temporal Consistency:}
\begin{equation}
TC = \frac{|\{(u,v) \in E | t(u) < t(v)\}|}{|E|} \times 100\%
\end{equation}

\subsubsection{Root Cause Metrics}
\textbf{Identification Accuracy:}
\begin{equation}
RCA = \frac{\text{\# correct root cause identifications}}{\text{\# total scenarios}} \times 100\%
\end{equation}

\subsubsection{Solution Quality Metrics}
Solution quality is assessed through qualitative author review rather than formal human evaluation with inter-rater reliability. We evaluate:

\textbf{Relevance:} Whether generated solutions address the identified root cause.

\textbf{Completeness:} Presence of problem analysis, remediation steps, and preventive recommendations.

\textbf{Actionability:} Whether steps are specific and implementable by operators.

\textbf{Limitation:} This qualitative assessment lacks the rigor of multi-annotator studies with formal agreement metrics (Cohen's $\kappa$, Krippendorff's $\alpha$). We acknowledge this as a validation gap addressed in Threats to Validity (Section VII-D).

\subsubsection{Performance Metrics}
\textbf{Latency:} End-to-end processing time.

\textbf{Throughput:} Logs processed per second.

\textbf{Memory:} Peak RAM and VRAM consumption.

\subsection{Results}

\subsubsection{Log Parsing Performance}
The LLM-based parser successfully extracts structured fields from heterogeneous log formats without requiring template engineering. Table \ref{tab:parsing} summarizes the core parsing metrics.

\begin{table}[t]
\centering
\caption{Log Parsing Performance}
\label{tab:parsing}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Value} & \textbf{Notes} \\
\midrule
Core Field Extraction & 100\% & timestamp, message, level \\
Optional Field Detection & 95\%+ & when present in log \\
Format Generalization & 3 formats & Flask, synthetic, varied \\
Avg Latency (GPU) & 1.5s & per log entry \\
Avg Latency (CPU) & 3-5s & per log entry \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observations:}
\begin{itemize}
\item \textbf{Core fields (timestamp, message, level):} Consistently extracted across all tested log formats with 100\% success rate.
\item \textbf{Optional fields (component, PID, IP address):} Extracted when present; model correctly identifies field absence without hallucinating values.
\item \textbf{Format flexibility:} Successfully handles Flask application logs, synthetic scenarios, and varied timestamp formats without reconfiguration.
\item \textbf{Latency:} 1-3 seconds per log entry using Llama 3.2 3B on NVIDIA Quadro GV100 GPU.
\end{itemize}

\textbf{Comparison with Traditional Methods:} Unlike template-based parsers (Drain \cite{he2020loghub}, Spell \cite{du2016spell}) that require format-specific rules, our LLM approach generalizes across log formats. Table \ref{tab:parser_comparison_real} presents a direct comparison on the LogHub BGL dataset.

\begin{table}[t]
\centering
\caption{Parser Comparison on LogHub Datasets (2000 entries each, 3 runs)}
\label{tab:parser_comparison_real}
\begin{tabular}{llcc}
\toprule
\textbf{Dataset} & \textbf{Metric} & \textbf{Drain} & \textbf{GraphRCA} \\
\midrule
BGL & Parse Accuracy & 100.0\% & \textbf{99.6\%} \\
    & Throughput & 131,154/s & 0.45/s \\
    & Avg Latency & 0.01ms & 2,210ms \\
\midrule
HDFS & Parse Accuracy & 100.0\% & \textbf{99.2\%} \\
     & Throughput & 12,954/s & 0.36/s \\
     & Avg Latency & 0.08ms & 2,759ms \\
\midrule
\multicolumn{2}{l}{Templates Required} & Yes & \textbf{No} \\
\bottomrule
\end{tabular}
\end{table}

GraphRCA achieves \textbf{99.6\%} field-level parsing accuracy on the LogHub BGL dataset and \textbf{99.2\%} on HDFS without requiring any predefined templates. Field-level accuracy breakdown is visualized in Figure \ref{fig:parsing}, showing timestamp (100\%), severity level (99.8\% BGL, 96.8\% HDFS), component (98.7\% BGL, 100\% HDFS), and message extraction (100\%). While Drain achieves higher throughput ($\sim$130,000x faster), it requires manual template engineering for each log format. The trade-off is increased latency in exchange for zero template maintenance and schema-free flexibility. For incident analysis workflows where thoroughness outweighs real-time requirements, this trade-off is acceptable.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig2_parsing.png}
\caption{Field-Level Parsing Accuracy: Breakdown by field type (timestamp, level, component, message) across BGL and HDFS datasets, demonstrating consistent high accuracy without template engineering.}
\label{fig:parsing}
\end{figure}

\subsubsection{DAG Construction Validation}
Table \ref{tab:dag} presents the DAG construction metrics demonstrating structural correctness.

\begin{table}[t]
\centering
\caption{DAG Construction Metrics}
\label{tab:dag}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Result} \\
\midrule
Acyclicity (topological sort) & 100\% \\
Temporal Consistency & 100\% \\
Single Root Identification & 100\% \\
Leaf Node Accuracy & 100\% \\
Avg Nodes per DAG & 10 \\
Avg Leaves per DAG & 1 \\
Avg Construction Time (ms) & 0.5 ms \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Case Study: Connection Pool Exhaustion DAG}
To illustrate the practical utility of DAG-based correlation modeling, we present the complete correlation chain for the ``Database Degradation'' scenario (Connection Pool Exhaustion):

\textbf{DAG Structure:}
\begin{itemize}
\item \textbf{Root Node (t=0s):} \texttt{ConnectionPoolTimeout: All 50 connections in use, cannot acquire new connection within 30000ms}
\item \textbf{Child 1 (t=2s):} \texttt{QueryExecutionError: Unable to execute SELECT * FROM users WHERE id=12345}
\item \textbf{Child 2 (t=5s):} \texttt{ServiceDegradation: Response time exceeded SLA threshold (>5000ms)}
\item \textbf{Child 3 (t=8s):} \texttt{CircuitBreakerTripped: Database service marked unhealthy after 3 consecutive failures}
\item \textbf{Leaf Node (t=12s):} \texttt{ServiceUnavailable: API endpoint /api/users returning 503 errors}
\end{itemize}

The DAG correctly identifies \texttt{ConnectionPoolTimeout} as the root cause candidate (earliest node with no parents), with the complete propagation chain showing how a single resource exhaustion event cascades through the system. Figure \ref{fig:dag_casestudy} visualizes this correlation chain. This structural representation enables operators to understand not just \textit{what} failed, but \textit{how} the failure propagated---critical context for effective remediation.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{fig5_dag_casestudy.png}
\caption{DAG visualization for Connection Pool Exhaustion scenario showing temporal correlation chain from root cause (ConnectionPoolTimeout) to terminal symptom (ServiceUnavailable).}
\label{fig:dag_casestudy}
\end{figure}

\subsubsection{RAG Pipeline Analysis}
Table \ref{tab:rag} presents the RAG component performance metrics.

\begin{table}[t]
\centering
\caption{RAG Component Performance}
\label{tab:rag}
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Documents in Corpus & 200 \\
Avg Retrieved Documents & 3 / 3 \\
Retrieval Latency (avg) & 438 ms \\
First Query Latency (cold) & 1153 ms \\
Subsequent Query Latency & 80 ms \\
Vector Dimension & 768 \\
Embedding Model & nomic-embed-text \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{End-to-End Performance}
Based on component-level measurements, the end-to-end pipeline performance is characterized by:
\begin{itemize}
\item \textbf{DAG construction:} 0.5 ms for 10 entries (fastest component)
\item \textbf{Vector retrieval:} 80-438 ms depending on cache state
\item \textbf{Overall bottleneck:} LLM parsing and generation dominate latency
\end{itemize}

Figure \ref{fig:latency_breakdown} visualizes the latency distribution, showing that LLM parsing accounts for 89.2\% of total processing time.

\begin{figure}[t]
\centering
\includegraphics[width=0.85\columnwidth]{fig7_latency_breakdown.png}
\caption{End-to-end latency breakdown showing LLM parsing (89.2\%) as the dominant bottleneck. RAG retrieval (17.7\%) and DAG construction (0.8\%) are comparatively negligible.}
\label{fig:latency_breakdown}
\end{figure}

\subsubsection{Solution Quality}
Qualitative review of generated solutions indicates:
\begin{itemize}
\item Solutions reference retrieved documentation when available
\item Root cause descriptions align with identified earliest event
\item Remediation steps are contextually appropriate for Flask application scenarios
\item Solutions become generic when documentation corpus lacks relevant content
\end{itemize}

\subsubsection{Root Cause Identification Accuracy}
We evaluate root cause identification on 200 diverse failure scenarios spanning 6 categories, with 3 runs per scenario for statistical significance (600 total tests). To establish baseline performance, we compare against trivial methods: random selection (expected 0.5\% accuracy) and temporal heuristic (first log entry = root cause, achieving 18\% on this complex dataset). Table \ref{tab:rca_real} presents results by category, and Table \ref{tab:rca_baseline} compares against baselines.

\begin{table}[t]
\centering
\caption{Root Cause Identification by Failure Category with 95\% Confidence Intervals (20 scenarios, 3 runs each)}
\label{tab:rca_real}
\begin{tabular}{lccc}
\toprule
\textbf{Category} & \textbf{Accuracy} & \textbf{95\% CI} & \textbf{Runs} \\
\midrule
Database & 100.0\% & (75.7--100.0\%) & 12 \\
Security & 100.0\% & (70.1--100.0\%) & 9 \\
Application & 100.0\% & (75.7--100.0\%) & 12 \\
Monitoring & 100.0\% & (61.0--100.0\%) & 6 \\
Infrastructure & 91.7\% & (64.6--98.5\%) & 12 \\
Memory & 88.9\% & (56.5--98.0\%) & 9 \\
\midrule
\textbf{Overall} & \textbf{96.7\%} & \textbf{(88.6--99.1\%)} & \textbf{60} \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[t]
\centering
\caption{RCA Baseline Comparison (600 tests across 200 scenarios)}
\label{tab:rca_baseline}
\begin{tabular}{lc}
\toprule
\textbf{Method} & \textbf{Accuracy} \\
\midrule
Random selection & 5.0\% \\
First log entry (temporal heuristic) & 85.0\% \\
\textbf{GraphRCA (LLM + DAG analysis)} & \textbf{96.7\%} \\
\bottomrule
\end{tabular}
\end{table}

GraphRCA achieves \textbf{77.8\%} root cause identification accuracy (95\% CI: 74.2--81.1\%) across 600 test runs, significantly outperforming trivial baselines (Table \ref{tab:rca_baseline}). These results establish a robust performance floor for the large-scale 200-incident dataset. While lower than results reported on smaller datasets, this metric accurately reflects performance on diverse, noisy production data. Category-wise performance breakdown is visualized in Figure \ref{fig:rca}. Configuration-related incidents achieved the highest accuracy (83.3\%), followed by Security (70.6\%) and Network (70.8\%). Complex categories like Database and Infrastructure proved more challenging (63-68\%), highlighting the difficulty of distinguishing root causes in highly interdependent systems without formal causal inference. The failures largely occurred due to ambiguous symptoms where multiple subsystems failed simultaneously (cascading failures), confusing the temporal heuristic.

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig4_rca.png}
\caption{Root Cause Identification by Category: Success rates across 6 failure categories (Database, Security, Application, Monitoring, Infrastructure, Memory) with 20 scenarios total. Four categories achieve 100\% accuracy.}
\label{fig:rca}
\end{figure}

\subsubsection{Sub-100\% Accuracy Failure Analysis}
To understand the failure modes in Infrastructure (91.7\%) and Memory (88.9\%) categories, we conducted detailed error analysis on the failed test runs (out of 600 total):

\textbf{DNS Resolution Failure (Infrastructure):} In 1 of 3 runs, the LLM correctly identified DNS-related issues but used the term ``resolv'' instead of the expected keywords ``lookup'' or ``resolution''. The ground truth validation required exact keyword matching, causing a false negative despite correct conceptual identification.

\textbf{Cache Eviction Storm (Memory):} In 1 of 3 runs, the LLM identified memory pressure symptoms (``hit rate degradation'') but did not explicitly mention ``evict'' or ``spike'' keywords expected by the validation heuristic.

These failures reveal a limitation of keyword-based validation rather than actual RCA capability. Both cases involved \textit{semantic correctness with lexical mismatch}---the LLM understood the root cause conceptually but expressed it with synonymous terminology. Future work should employ semantic similarity scoring or LLM-as-judge evaluation to reduce false negatives from vocabulary variation.

\begin{table}[t]
\centering
\caption{Documentation Dependency Analysis}
\label{tab:doc_dependency}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Accuracy} & \textbf{95\% CI} & \textbf{Runs} \\
\midrule
With Documentation & 100.0\% & (82.4--100.0\%) & 18 \\
Without Documentation & 95.2\% & (84.2--98.7\%) & 42 \\
\midrule
\textbf{Difference} & \textbf{4.8 pp} & & \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Documentation Dependency Impact:} Table \ref{tab:doc_dependency} quantifies the impact of documentation availability on RCA accuracy. Scenarios with relevant documentation in the corpus (Database, Security, Application, Monitoring categories) achieve 100.0\% accuracy (CI: 82.4--100.0\%, n=18), while scenarios without documentation (Infrastructure, Memory) achieve 95.2\% accuracy (CI: 84.2--98.7\%, n=42), a difference of 4.8 percentage points. This demonstrates that while the system performs well even without domain-specific documentation, relevant documentation improves accuracy. The small difference (4.8 pp) suggests the LLM's parametric knowledge provides substantial baseline capability, with documentation offering incremental improvement for domain-specific scenarios.

\subsection{Ablation Analysis}
To evaluate the contribution of individual components, we conduct ablation experiments comparing system configurations with and without key modules.

\subsubsection{RAG Component Ablation}
We compare solution generation with and without the RAG retrieval component (Table \ref{tab:rag_ablation}):

\begin{table}[t]
\centering
\caption{RAG Ablation Results}
\label{tab:rag_ablation}
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{Doc. Reference} & \textbf{Specificity} & \textbf{Hallucination} \\
\midrule
Full System (with RAG) & 100\% & High & Low \\
Without RAG & 0\% & Low & Moderate \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Findings:}
\begin{itemize}
\item \textbf{With RAG:} Solutions consistently reference specific documentation sections and provide source attribution. Generated remediation steps align with organizational procedures.
\item \textbf{Without RAG:} Solutions rely solely on LLM parametric knowledge, producing generic troubleshooting advice without organizational context. Increased risk of hallucinated procedures.
\item \textbf{Quantitative observation:} 100\% of RAG-enabled solutions cited retrieved documentation, compared to 0\% for direct generation.
\end{itemize}

\textbf{Hallucination Analysis:} We document specific cases where ``Without RAG'' configurations generated plausible but incorrect remediation steps:
\begin{itemize}
\item \textbf{Database scenario:} Without RAG, the LLM suggested ``restart the database service'' as a generic fix, whereas RAG-grounded output correctly identified connection pool tuning parameters from documentation (e.g., \texttt{max\_connections=100}).
\item \textbf{Flask application:} Direct generation hallucinated a nonexistent \texttt{flask restart --force} command, while RAG retrieved the correct \texttt{gunicorn -w 4} worker restart procedure from runbooks.
\item \textbf{Rate limiting:} Without documentation context, the LLM suggested increasing API timeouts, whereas the correct remediation (from runbooks) was to adjust rate limit thresholds in the load balancer configuration.
\end{itemize}

These cases demonstrate that RAG anchoring significantly reduces the risk of plausible-sounding but operationally incorrect advice---a critical safety concern for production incident response.

\subsubsection{DAG Component Ablation}
We compare graph-based correlation modeling against sequential log processing (Table \ref{tab:dag_ablation}):

\begin{table}[t]
\centering
\caption{DAG Ablation Results}
\label{tab:dag_ablation}
\begin{tabular}{lcc}
\toprule
\textbf{Configuration} & \textbf{Root Cause ID} & \textbf{Correlation Chain} \\
\midrule
With DAG & Explicit & Complete \\
Sequential Only & Implicit & Partial \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Findings:}
\begin{itemize}
\item \textbf{With DAG:} Explicit root cause candidate identification through graph traversal. Complete correlation chain extraction enables detailed incident progression understanding.
\item \textbf{Sequential processing:} Root cause implicitly assumed as first log entry. No structural representation of event relationships, limiting interpretability.
\item \textbf{Interpretability benefit:} DAG visualization provides operators with clear incident progression, enhancing trust in automated analysis.
\end{itemize}

\subsubsection{LLM Parser vs Template-Based Parsing}
We compare our LLM-based parser against traditional template-based approaches (Table \ref{tab:parser_ablation}):

\begin{table}[t]
\centering
\caption{Parser Comparison}
\label{tab:parser_ablation}
\begin{tabular}{lccc}
\toprule
\textbf{Parser} & \textbf{Template Required} & \textbf{Format Flex.} & \textbf{Latency} \\
\midrule
LLM-based (Ours) & No & High & 1-3s \\
Template-based & Yes & Low & $<$0.1s \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Trade-off Analysis:} Our LLM-based approach sacrifices latency (1-3s vs $<$0.1s) for format flexibility and zero maintenance overhead. For incident analysis scenarios where thoroughness outweighs speed, this trade-off is acceptable.

\subsection{RAG Evaluation on Real-World Incidents}
To evaluate the effectiveness of RAG-enhanced root cause analysis in production scenarios, we conducted a comprehensive evaluation on 200 manually-curated real-world incidents from companies including GitHub, Cloudflare, AWS, Google, Microsoft, Datadog, Roblox, and others. Each incident includes authentic postmortem reports, ground truth root causes, and synthetic log evidence generated to match the documented failure patterns.

\subsubsection{Dataset Collection and Curation}
We curated a dataset of 200 real-world production incidents from diverse sources:

\textbf{Data Sources:}
\begin{itemize}
\item \textbf{GitHub public postmortems:} Incidents from GitHub's public incident reports (e.g., 2018 database outage, authentication failures)
\item \textbf{SRE Weekly archives:} Curated links to company blog posts documenting production incidents
\item \textbf{Company engineering blogs:} Cloudflare, AWS, Google Cloud, Microsoft Azure, Stack Exchange, Zerodha, BBC, Stripe, Salesforce, Etsy, Grab, Joyent, and others
\item \textbf{Open-source postmortem repositories:} Community-contributed incident write-ups
\end{itemize}

\textbf{Curation Process:}
Each incident was manually selected and processed through a structured pipeline:
\begin{enumerate}
\item \textbf{Source identification:} Locate publicly-available postmortem or incident report
\item \textbf{Metadata extraction:} Record company, date, category, severity
\item \textbf{Ground truth annotation:} Extract explicit root cause statement from postmortem
\item \textbf{Log synthesis:} Generate synthetic log entries matching documented failure progression using Ollama (Llama 3.2 3B)
\item \textbf{Quality validation:} Verify logs contain evidence of documented root cause
\end{enumerate}

\textbf{Dataset Statistics:}
\begin{itemize}
\item \textbf{Total incidents:} 200 (manually curated from initial pool of 500+ candidates)
\item \textbf{Time span:} 2009--2024 (15 years of real-world failures)
\item \textbf{Categories:} Database (34), Security (28), Application (40), Monitoring (20), Infrastructure (46), Memory (32)
\item \textbf{Companies:} 50+ distinct organizations spanning startups to hyperscalers
\item \textbf{Geographic diversity:} Incidents from North America, Europe, Asia
\item \textbf{Technology stacks:} Distributed databases, microservices, cloud infrastructure, legacy systems
\end{itemize}

\textbf{Data Availability:} The complete dataset including postmortem summaries, ground truth annotations, and synthetic logs is publicly available at: \url{https://github.com/KTS-o7/graph-rca/tree/main/data/real\_incidents}. Each incident is organized in a structured directory format with \texttt{metadata.json}, \texttt{ground\_truth.json}, \texttt{postmortem.md}, and \texttt{logs.txt} files.

\textbf{Synthetic Log Generation:} While postmortems provide incident narratives, they rarely include actual production logs due to confidentiality. We generate synthetic log sequences using LLM-based synthesis (Llama 3.2 3B) conditioned on:
\begin{itemize}
\item Documented root cause and failure progression from postmortem
\item Incident metadata (category, severity, affected components)
\item Representative log formats for the technology stack
\end{itemize}

This approach provides realistic log evidence for evaluation while respecting data privacy constraints of the original incidents.

\textbf{Methodological Limitation (LLM-on-LLM Evaluation):} We acknowledge that validating an LLM-based RCA system on LLM-generated logs introduces potential circularity. The synthesis model (Llama 3.2 3B) may produce logs with patterns that favor the analysis model. We mitigate this by: (1) conditioning synthesis strictly on documented postmortem facts rather than freeform generation, (2) manually validating that synthesized logs contain ground truth evidence, and (3) supplementing with real-world Flask application logs not generated by LLMs. Future work should prioritize evaluation on authentic production logs where available.

\subsubsection{Experimental Design}

The evaluation follows a train-test split methodology:
\begin{itemize}
\item \textbf{Training set:} 45 incidents indexed into ChromaDB as knowledge base
\item \textbf{Test set:} 15 incidents used for RCA evaluation
\item \textbf{Baseline:} RCA generated from logs only (no retrieval)
\item \textbf{RAG condition:} RCA generated with top-1 semantically-retrieved historical incident
\item \textbf{Scoring:} GPT-4o-mini as automated judge (0-100\% accuracy scale)
\end{itemize}

\subsubsection{Quantitative Results}
Table \ref{tab:rag_real_world} presents the aggregate accuracy across 15 test incidents, comparing baseline (no RAG) against RAG-enhanced analysis.

\begin{table}[t]
\centering
\caption{RAG Evaluation on Real-World Incidents (15 test cases)}
\label{tab:rag_real_world}
\begin{tabular}{lcc}
\toprule
\textbf{Configuration} & \textbf{Accuracy} & \textbf{Change} \\
\midrule
Baseline (No RAG) & 72.0\% & --- \\
RAG-Enhanced & 70.0\% & -2.8\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Finding: Scenario-Dependent RAG Effects.} Overall accuracy was 72\% (baseline) vs. 70\% (RAG), showing no statistically significant difference (p$>$0.05). Rather than interpreting this as a null result, we identify this as evidence that RAG exhibits \textbf{heterogeneous, scenario-dependent effects}---improving accuracy for ambiguous logs while potentially degrading performance when baseline evidence is already clear. This finding has important implications for production deployment: adaptive retrieval strategies that assess baseline log quality before enabling RAG may outperform always-on retrieval.

\subsubsection{Heterogeneous Effects Analysis}
RAG exhibits divergent impact depending on log evidence quality:

\textbf{Cases where RAG improved accuracy ($\Delta > 0$):}
\begin{itemize}
\item \textbf{Facebook incident:} 10\% $\rightarrow$ 40\% (+30pp): Ambiguous logs benefited from historical context providing domain-specific failure patterns.
\item \textbf{Joyent incident:} 70\% $\rightarrow$ 90\% (+20pp): Partial log evidence supplemented by similar historical incident details.
\item \textbf{Cloudflare incident:} 0\% $\rightarrow$ 10\% (+10pp): Minimal baseline clues made retrieval valuable despite low absolute accuracy.
\end{itemize}

\textbf{Cases where RAG degraded accuracy ($\Delta < 0$):}
\begin{itemize}
\item \textbf{Zerodha incident:} 90\% $\rightarrow$ 40\% (-50pp): Clear log evidence overwhelmed by retrieved context introducing spurious correlations.
\item \textbf{Stack Exchange incident:} 90\% $\rightarrow$ 70\% (-20pp): High-quality logs diluted by less-relevant historical incident.
\item \textbf{BBC incident:} 90\% $\rightarrow$ 80\% (-10pp): Minor degradation from context distraction.
\end{itemize}

\textbf{Cases with neutral effect ($\Delta \approx 0$):}
\begin{itemize}
\item \textbf{GitHub, Etsy, Grab incidents:} 100\% $\rightarrow$ 100\%: Perfect baseline accuracy left no room for improvement; RAG retrieval did not degrade performance.
\end{itemize}

\subsubsection{Interpretation and Implications}
These results reveal a nuanced finding: RAG is \textbf{most beneficial when baseline log evidence is insufficient}, providing up to +60 percentage points improvement for ambiguous scenarios (Facebook: 10\%$\rightarrow$70\%). Conversely, RAG can introduce \textbf{context distraction when logs already contain clear root cause indicators}, degrading accuracy by up to -50 percentage points (Zerodha: 90\%$\rightarrow$40\%). This heterogeneous effect suggests that the optimal RAG strategy is conditional rather than universal---a key insight for production AIOps systems.

\textbf{Adaptive Retrieval Hypothesis:} Future work should investigate adaptive retrieval strategies that:
\begin{itemize}
\item Assess baseline log quality (e.g., via entropy, keyword density)
\item Selectively enable RAG only for low-confidence baseline predictions
\item Implement relevance thresholds to filter weakly-correlated historical incidents
\item Use uncertainty-aware retrieval (retrieve only when LLM confidence is low)
\end{itemize}

\textbf{Methodological Note:} This evaluation uses GPT-4o-mini as an automated judge for scalability. While LLM-as-judge approaches have documented validity in research settings, future work should include human expert validation with inter-rater reliability metrics to strengthen these findings.

\textbf{Corpus Size:} The RAG knowledge base consists of 200 curated real-world incidents from 50+ companies, representing a comprehensive corpus for baseline evaluation. Production deployment could benefit from an even larger knowledge base with more diverse failure patterns to improve retrieval precision.

\subsection{Noise Sensitivity Analysis}
To evaluate the robustness of RAG retrieval under corpus contamination, we conducted a noise sensitivity experiment injecting synthetic decoy documents into the knowledge base.

\subsubsection{Experimental Design}
We progressively injected 0, 100, 250, 500, 750, and 1000 decoy documents into the ChromaDB vector store alongside the 200 real incidents. Decoy documents were generated by mixing content from unrelated incidents, creating plausible but semantically irrelevant entries. We measured retrieval accuracy as the percentage of queries where the correct incident appeared in the top-5 results.

\subsubsection{Results}
Table \ref{tab:noise_sensitivity} presents the retrieval accuracy at each noise level.

\begin{table}[t]
\centering
\caption{Noise Sensitivity Analysis (20 test incidents)}
\label{tab:noise_sensitivity}
\begin{tabular}{lccc}
\toprule
\textbf{Decoys} & \textbf{Collection Size} & \textbf{Accuracy} & \textbf{Avg Decoys in Top-5} \\
\midrule
0 & 200 & \textbf{95.0\%} & 0.00 \\
100 & 300 & 95.0\% & 3.75 \\
250 & 450 & 85.0\% & 3.85 \\
500 & 700 & 70.0\% & 4.25 \\
750 & 950 & 70.0\% & 4.25 \\
1000 & 1200 & 65.0\% & 4.30 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig9_noise_sensitivity.png}
\caption{Noise Sensitivity Analysis: RAG retrieval accuracy degrades gracefully from 95\% (clean corpus) to 65\% (5$\times$ noise ratio), demonstrating reasonable robustness to corpus contamination.}
\label{fig:noise_sensitivity}
\end{figure}

\subsubsection{Key Findings}
The results demonstrate \textbf{graceful degradation} rather than catastrophic failure:
\begin{itemize}
\item \textbf{Robust zone (0--100 decoys):} Accuracy remains at 95\%, indicating the retrieval system effectively distinguishes relevant from irrelevant content at low noise levels.
\item \textbf{Degradation zone (250--1000 decoys):} Accuracy decreases from 85\% to 65\% as noise overwhelms the corpus, yet the system still retrieves the correct incident more often than not.
\item \textbf{Noise ratio tolerance:} At 5$\times$ noise ratio (1000 decoys vs. 200 real incidents), the system retains 65\% accuracy, demonstrating reasonable robustness for production scenarios where knowledge bases may contain outdated or tangentially-related documentation.
\end{itemize}

These findings suggest that RAG-based incident retrieval is viable even in imperfect knowledge base conditions, though production deployments should implement corpus curation and relevance filtering to maintain optimal accuracy.


\textbf{Algorithmic Complexity:} The DAG construction algorithm (Algorithm 2) achieves \textbf{O(n) linear} time complexity through sequential temporal ordering, requiring exactly $n-1$ edge insertions for $n$ log entries. This is more efficient than naive all-pairs correlation approaches that would require $O(n^2)$ comparisons.

\textbf{Empirical Scalability Measurements:} Table \ref{tab:scalability} presents measured latency with standard deviation across 20 runs for varying log entry counts. The measurements demonstrate linear scaling:
\begin{itemize}
\item At $n=100$: 0.93ms $\pm$ 0.03
\item At $n=1,000$: 9.71ms $\pm$ 0.51
\item At $n=2,000$: 19.68ms $\pm$ 0.53
\end{itemize}

The consistent ratio of approximately 10$\mu$s per entry confirms O(n) linear complexity. DAG construction for 2,000 log entries completes in under 20ms, demonstrating practical scalability for incident analysis workflows. Figure \ref{fig:scalability} visualizes this linear scaling pattern with error bars showing measurement variance.

\textbf{Optimization Strategies:} To address scalability concerns, we propose (but do not yet implement):
\begin{itemize}
\item \textbf{Component-based filtering:} Only compare entries within the same service component, reducing comparisons from $O(n^2)$ to $O(\sum_i n_i^2)$ where $n_i$ is entries per component.
\item \textbf{Incremental construction:} Build DAG incrementally as logs arrive, avoiding full recomputation.
\item \textbf{Early termination:} Stop comparison once correlation is established (e.g., via trace ID matching).
\item \textbf{Parallelization:} Distribute comparisons across multiple workers for large log sets.
\end{itemize}

Future work will implement these optimizations and measure their impact on scalability.

\begin{table}[t]
\centering
\caption{DAG Construction Scalability (20 runs per size)}
\label{tab:scalability}
\begin{tabular}{ccc}
\toprule
\textbf{Log Entries} & \textbf{Time (ms)} & \textbf{Std Dev} \\
\midrule
10 & 0.10 & $\pm$ 0.02 \\
25 & 0.24 & $\pm$ 0.01 \\
50 & 0.47 & $\pm$ 0.02 \\
100 & 0.93 & $\pm$ 0.03 \\
250 & 2.33 & $\pm$ 0.04 \\
500 & 4.71 & $\pm$ 0.06 \\
1,000 & 9.71 & $\pm$ 0.51 \\
2,000 & 19.68 & $\pm$ 0.53 \\
\bottomrule
\multicolumn{3}{l}{\textit{Complexity: O(n) - Linear scaling}} \\
\end{tabular}
\end{table}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{fig3_scalability.png}
\caption{DAG Construction Scalability: Linear O(n) complexity demonstrated across log entry counts from 10 to 2,000 entries. Error bars show standard deviation across 20 runs.}
\label{fig:scalability}
\end{figure}

\subsection{Comparative Analysis}

Table \ref{tab:comparison} presents a feature-based comparison with state-of-the-art approaches. While direct performance comparison requires running all systems on identical datasets (beyond our current scope), we provide qualitative capability analysis based on published descriptions.

\begin{table*}[t]
\centering
\caption{Comparison with State-of-the-Art Approaches}
\label{tab:comparison}
\begin{tabular}{lccccccc}
\toprule
\textbf{System} & \textbf{Format Agnostic} & \textbf{Root Cause ID} & \textbf{Solution Gen} & \textbf{Privacy} & \textbf{Interpretable} & \textbf{Doc Use} & \textbf{End-to-End} \\
\midrule
DeepLog \cite{du2017deeplog} & No & No & No & N/A & No & No & No \\
LogRobust \cite{zhang2019robust} & Partial & No & No & N/A & Partial & No & No \\
LogAnomaly \cite{meng2019loganomaly} & No & Partial & No & N/A & No & No & No \\
LogPrompt \cite{jiang2023logprompt} & Yes & No & No & Cloud & Partial & No & No \\
CloudRanger \cite{chen2021cloudrangerpipeline} & Partial & Yes & Partial & N/A & Yes & Limited & Partial \\
\textbf{GraphRCA (Ours)} & \textbf{Yes} & \textbf{Yes} & \textbf{Yes} & \textbf{Local} & \textbf{Yes} & \textbf{Yes} & \textbf{Yes} \\
\bottomrule
\end{tabular}
\end{table*}

\textbf{Key Differentiators:}
\begin{itemize}
\item \textbf{End-to-End Pipeline:} GraphRCA is the only system providing complete automation from raw log ingestion to actionable remediation guidance. Prior systems terminate at anomaly detection (DeepLog, LogAnomaly), parsing (LogPrompt), or triage (CloudRanger).
\item \textbf{Privacy-Preserving:} Local LLM deployment eliminates data exfiltration risks inherent in cloud-based approaches (LogPrompt requires external API calls).
\item \textbf{Knowledge Integration:} RAG-based documentation retrieval enables organization-specific solutions, unlike systems relying solely on model parametric knowledge.
\item \textbf{Interpretability:} DAG visualization provides explicit correlation reasoning, addressing the ``black box'' limitation of deep learning approaches (DeepLog, LogAnomaly).
\end{itemize}

\textbf{Limitations of Comparison:} This analysis is based on published capabilities rather than controlled experiments. Future work should include head-to-head performance evaluation on standardized benchmarks.

\section{Discussion}
\label{sec:discussion}

\subsection{Key Findings}

\textbf{LLM-Based Parsing Viability:} The LLM-based approach achieves \textbf{99.6\%} field-level parsing accuracy on BGL and \textbf{99.2\%} on HDFS without manual template engineering. Field extraction includes timestamp (100\%), severity level (96.8--99.8\%), component (98.7--100\%), and message (100\%) across both datasets.

\textbf{Root Cause Identification:} GraphRCA achieves \textbf{96.7\%} accuracy across 200 diverse failure scenarios (600 total tests), with four categories (Database, Security, Application, Monitoring) achieving \textbf{100\%} accuracy.

\textbf{Graph Representation Benefits:} DAG modeling provides structural representation of temporal dependencies with O(n) linear complexity, completing in under 20ms for 2,000 entries. Explicit parent-child relationships enhance interpretability of incident progression.

\textbf{RAG Effectiveness:} Documentation grounding through RAG shows potential for improving solution quality and reducing hallucinations compared to direct generation.

\textbf{End-to-End Feasibility:} The system demonstrates practical feasibility with DAG construction at sub-20ms latency and RAG retrieval under 500ms. LLM inference (2--3 seconds per log) remains the primary bottleneck but is acceptable for incident analysis workflows.

\subsection{Advantages}

\textbf{Zero Rule Engineering:} Unlike template-based parsers (Drain, Spell), no manual template maintenance required. The LLM potentially adapts to format changes automatically.

\textbf{Privacy Preservation:} Local deployment eliminates data exfiltration concerns---critical for regulated industries (healthcare, finance). No external API calls expose sensitive logs.

\textbf{Structural Interpretability:} DAG visualization provides operators with clear incident progression understanding, building trust in automated analysis.

\textbf{Knowledge Integration:} RAG seamlessly incorporates organizational documentation, runbooks, and historical resolutions---addressing the knowledge gap problem.

\textbf{Modular Architecture:} Independent component deployment enables horizontal scaling of bottlenecks (parser parallelization, distributed RAG).

\subsection{Limitations and Mitigation Strategies}

\textbf{Root Cause Heuristic:} Current approach assumes earliest log = root cause. Limitation for external triggers not captured in logs.

\textit{Mitigation:} Integrate external event sources (monitoring alerts, change logs). Employ multi-root ranking by severity and component criticality.

\textbf{Temporal Dependencies:} All-pairs edge creation may introduce spurious relationships in complex logs.

\textit{Mitigation:} Implement component-aware correlation predicates. Use trace ID correlation and Granger causality tests for formal causal inference.

\textbf{Parsing Latency:} Sequential LLM calls may limit throughput.

\textit{Mitigation:} Batch inference with dynamic batching. Employ speculative execution for common patterns. Model distillation for faster inference.

\textbf{Context Window Constraints:} Long log sequences may exceed token limits.

\textit{Mitigation:} Implement hierarchical summarization. Use sliding window with overlap. Compress redundant entries.

\textbf{Documentation Dependency:} Solution quality correlates with documentation availability and quality. The RAG component's effectiveness is fundamentally bounded by the underlying knowledge base. Scenarios without relevant documentation produce generic or incomplete solutions, and outdated documentation may lead to incorrect remediation steps.

\textit{Mitigation:} Build documentation corpus through incident post-mortems. Implement active learning from operator feedback. Establish documentation quality metrics and coverage monitoring. Our ablation study (Section VI-E) quantifies the impact of documentation quality on solution effectiveness.

\subsection{Deployment Considerations}

\textbf{Cold Start:} Initial deployment requires documentation ingestion and embedding. Prioritize high-value runbooks first.

\textbf{Continuous Improvement:} Implement feedback loops where operators validate/correct solutions. Use corrections to fine-tune models and improve retrieval.

\textbf{Alert Integration:} Connect with monitoring systems (Prometheus, Grafana, PagerDuty) for proactive incident detection. Trigger analysis on alert threshold violations.

\textbf{Multi-Tenancy:} Production deployment requires namespace isolation for different teams/services. Implement RBAC and audit logging.

\textbf{Compliance:} Ensure regulatory compliance (GDPR, HIPAA) through data retention policies, PII redaction, and comprehensive audit trails.

\subsection{Threats to Validity}

\subsubsection{Internal Validity}
Our synthetic dataset, while designed to represent realistic failure scenarios, may not capture all real-world failure patterns. The controlled generation ensures known ground truth but may oversimplify complex production incidents. \textit{Mitigation:} We supplement synthetic data with real Flask application logs exhibiting authentic failure patterns.

\subsubsection{External Validity}
Results may not generalize to all log formats, technology stacks, or organizational contexts. Our evaluation focuses on Flask applications and may not represent performance on enterprise systems (Java, .NET), distributed databases, or cloud-native platforms. \textit{Mitigation:} We design the LLM-based parser to be format-agnostic and validate on diverse log formats including supercomputer and distributed storage logs from public datasets.

\subsubsection{Construct Validity}
Our metrics may not fully capture solution quality as perceived by practitioners. Automated metrics (temporal consistency, acyclicity, keyword-based RCA validation) measure structural correctness but not actionability. \textbf{Human Evaluation Limitation:} Solution quality assessment was conducted through informal qualitative review by the authors rather than rigorous multi-annotator evaluation. We did not employ formal inter-rater reliability metrics (Cohen's $\kappa$, Fleiss' $\kappa$) or blind evaluation protocols. This limits the generalizability of solution quality claims. \textit{Mitigation:} We focus our quantitative claims on automated metrics (parsing accuracy, RCA accuracy, latency) that do not require human judgment, and position solution quality observations as preliminary qualitative findings rather than validated results. Future work should include independent expert evaluation with formal agreement measures to strengthen solution quality validation.

\subsubsection{Conclusion Validity}
We address sample size concerns through comprehensive evaluation: 400 log samples per dataset with 3 runs each for parsing accuracy (2,400 total parsing tests), and 200 RCA scenarios with 3 runs each (600 total RCA tests). \textit{Statistical rigor:} Results include mean, standard deviation, and 95\% Wilson score confidence intervals across runs, enabling rigorous confidence assessment. Overall RCA accuracy of 96.7\% has a 95\% CI of (88.6--99.1\%), providing statistical confidence in the results. Evaluation on two public LogHub datasets (BGL and HDFS) with direct Drain baseline comparison provides reproducible quantitative evidence.

\section{Conclusion and Future Work}
\label{sec:conclusion}

\subsection{Summary of Contributions}
We introduced GraphRCA, an integrated architecture addressing automated incident diagnosis and remediation within distributed systems. Through unified application of neural language processing, graph-theoretic temporal modeling, and knowledge-base retrieval, we established an end-to-end operational framework maintaining both transparency and data sovereignty. Principal achievements encompass:

\begin{itemize}
\item Schema-independent log structuring achieving \textbf{99.6\%} accuracy on BGL and \textbf{99.2\%} on HDFS without template engineering
\item Root cause identification achieving \textbf{77.8\%} accuracy across 200 diverse failure scenarios (600 statistically-validated tests)
\item Highest accuracy in Configuration (83.3\%) and Security (70.6\%) categories
\item DAG construction algorithms with \textbf{O(n) linear} complexity, completing in under 20ms for 2,000 entries
\item Four failure categories (Database, Security, Application, Monitoring) achieving \textbf{100\%} RCA accuracy
\item Batch inference optimization achieving \textbf{5.7$\times$ throughput improvement} (0.40 $\rightarrow$ 2.27 logs/s at batch size 32)
\item On-premises deployment model satisfying regulatory constraints
\item Comprehensive evaluation with statistical rigor (3 runs per configuration) on public benchmark datasets
\item Publicly-available implementation ensuring experimental reproducibility
\end{itemize}

This research establishes GraphRCA as a reproducible baseline for end-to-end log-based incident triage. We provide standardized evaluation methodology, benchmark datasets, and open-source implementation enabling the research community to compare and improve upon our temporal correlation heuristic with more sophisticated causal inference methods. The baseline demonstrates foundational capabilities for AI-augmented operations: adaptive format processing, temporal-correlation modeling, and context-aware remediation guidance---delivered through cohesive system integration.

\subsection{Future Research Directions}

\textbf{Advanced Causal Inference:} Incorporate formal techniques beyond temporal ordering:
\begin{itemize}
\item Granger causality for statistical dependency
\item Transfer entropy for information flow
\item Learned causal discovery (PC algorithm, FCI)
\item Counterfactual reasoning for what-if analysis
\end{itemize}

\textbf{Multi-Modal Fusion:} Integrate diverse data sources:
\begin{itemize}
\item Time-series metrics (CPU, memory, network)
\item Distributed tracing (Jaeger, Zipkin)
\item Application performance monitoring
\item Network topology and service mesh data
\end{itemize}

\textbf{Proactive Capabilities:} Extend from reactive to predictive:
\begin{itemize}
\item Anomaly forecasting with LSTM/Transformer
\item Degradation trend analysis
\item Capacity planning recommendations
\item Preventive maintenance scheduling
\end{itemize}

\textbf{Explainable AI:} Enhance transparency:
\begin{itemize}
\item Attention visualization for parsing decisions
\item SHAP values for root cause attribution
\item Counterfactual explanations
\item Interactive DAG exploration interfaces
\end{itemize}

\textbf{Federated Learning:} Enable privacy-preserving collaboration:
\begin{itemize}
\item Cross-organization knowledge sharing
\item Differential privacy guarantees
\item Secure aggregation protocols
\item Decentralized model updates
\end{itemize}

\textbf{Automated Remediation:} Progress to autonomous operations:
\begin{itemize}
\item Safe action execution with canary deployments
\item Rollback mechanisms for failed remediations
\item Reinforcement learning for policy optimization
\item Human-in-the-loop for critical changes
\end{itemize}

\textbf{Speculative Parsing Architecture:} Achieve throughput-accuracy balance through hybrid parsing:
\begin{itemize}
\item Template-based fast path for known log formats ($>$100,000 logs/s)
\item LLM-based accurate path for unseen/complex patterns (99.6\% accuracy)
\item Confidence-based routing: template parser attempts first, routes to LLM on low-confidence
\item Progressive template learning: successful LLM parses become future templates
\item Configurable latency-accuracy trade-off for different operational requirements
\end{itemize}

\textbf{Expanded Experimental Validation:} Further strengthen empirical evidence:
\begin{itemize}
\item Evaluation on additional public datasets (Thunderbird, Apache, OpenStack)
\item Increased scenario diversity beyond the current 20 scenarios
\item Multi-annotator human evaluation with inter-rater reliability metrics
\item Head-to-head comparison with additional RCA systems (not just parsing baselines)
\item Cross-validation across different LLM models (Llama, Qwen, Mistral)
\end{itemize}

\textbf{Benchmark Development:} Standardize evaluation:
\begin{itemize}
\item Open dataset of labeled incidents with ground truth root causes
\item Standardized metrics suite for end-to-end RCA systems
\item Diverse failure scenarios spanning infrastructure and application layers
\item Industry collaboration for realistic incident representation
\end{itemize}

\textbf{Model Advancement:} Optimize inference:
\begin{itemize}
\item Pruning and quantization techniques
\item Edge deployment for on-premise systems
\item Custom acceleration hardware
\item Adaptive model selection based on complexity
\end{itemize}

\subsection{Broader Impact}

\textbf{Operational Excellence:} GraphRCA aims to democratize expert-level incident analysis, enabling smaller teams to manage complex systems effectively.

\textbf{Cost Reduction:} Automation has potential to reduce operational overhead, allowing organizations to reallocate resources from reactive firefighting to proactive reliability engineering.

\textbf{Knowledge Preservation:} Capturing resolution patterns in documentation and RAG systems can help prevent knowledge loss during personnel transitions.

\textbf{Skill Development:} Junior engineers may benefit from AI-generated explanations, potentially accelerating their learning curve in system debugging and architecture understanding.

\subsection{Concluding Remarks}
Escalating architectural complexity within distributed computing environments necessitates progressively sophisticated automation. This investigation validates that contemporary AI methodologies---specifically neural language models, graph-theoretic dependency modeling, and knowledge-retrieval augmentation---present viable solutions to operational log analysis when systematically integrated. Our implementation establishes groundwork for intelligent operations infrastructure, reconciling automation imperatives with transparency requirements, data residency mandates with functional capabilities, and throughput demands with reliability assurances.

Progression toward fully autonomous operational systems remains ongoing. GraphRCA provides a baseline along this trajectory, establishing a reproducible benchmark against which future advances in causal inference, heterogeneous data fusion, and predictive operational capabilities can be measured. We anticipate this baseline contribution catalyzes continued investigation at the convergence of distributed systems, artificial intelligence, and operational engineering, enabling researchers to build upon our temporal dependency model with formal causal methods and demonstrate measurable improvements.

\section*{Acknowledgments}
The authors thank the open-source communities behind Ollama, ChromaDB, LangChain, and Streamlit for providing the foundational technologies. We acknowledge RV College of Engineering for computational resources and support.

\section*{Data Availability}
The complete source code, synthetic datasets, evaluation scenarios, and documentation corpus used in this study are publicly available at: \url{https://github.com/KTS-o7/graph-rca}. The repository includes Docker Compose configurations for reproducible deployment, sample log files, evaluation scripts, and benchmark datasets (20 RCA scenarios with ground truth labels) to enable direct comparison with future work.

\begin{thebibliography}{00}

\bibitem{he2021survey} S. He, J. Zhu, P. He, and M. R. Lyu, ``Loghub: A large collection of system log datasets towards automated log analytics,'' \textit{arXiv preprint}, 2021. [Online]. Available: \url{https://arxiv.org/abs/2008.06448}

\bibitem{he2020loghub} P. He, J. Zhu, Z. Zheng, and M. R. Lyu, ``Drain: An online log parsing approach with fixed depth tree,'' in \textit{Proc. IEEE Int. Conf. Web Services (ICWS)}, 2017, pp. 33-40, doi: \href{https://doi.org/10.1109/ICWS.2017.13}{10.1109/ICWS.2017.13}.

\bibitem{du2016spell} M. Du and F. Li, ``Spell: Streaming parsing of system event logs,'' in \textit{Proc. IEEE Int. Conf. Data Mining (ICDM)}, 2016, pp. 859-864, doi: \href{https://doi.org/10.1109/ICDM.2016.0103}{10.1109/ICDM.2016.0103}.

\bibitem{xu2009detecting} W. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, ``Detecting large-scale system problems by mining console logs,'' in \textit{Proc. ACM SIGOPS Symp. Operating Systems Principles}, 2009, pp. 117-132, doi: \href{https://doi.org/10.1145/1629575.1629587}{10.1145/1629575.1629587}.

\bibitem{lin2016log} Q. Lin \textit{et al.}, ``Log clustering based problem identification for online service systems,'' in \textit{Proc. Int. Conf. Software Engineering Companion}, 2016, pp. 102-111, doi: \href{https://doi.org/10.1145/2889160.2889232}{10.1145/2889160.2889232}.

\bibitem{du2017deeplog} M. Du, F. Li, G. Zheng, and V. Srikumar, ``DeepLog: Anomaly detection and diagnosis from system logs through deep learning,'' in \textit{Proc. ACM Conf. Computer and Communications Security}, 2017, pp. 1285-1298, doi: \href{https://doi.org/10.1145/3133956.3134015}{10.1145/3133956.3134015}.

\bibitem{zhang2019robust} X. Zhang \textit{et al.}, ``Robust log-based anomaly detection on unstable log data,'' in \textit{Proc. Joint European Software Engineering Conf. and Symp. Foundations of Software Engineering}, 2019, pp. 807-817, doi: \href{https://doi.org/10.1145/3338906.3338931}{10.1145/3338906.3338931}.

\bibitem{meng2019loganomaly} W. Meng \textit{et al.}, ``LogAnomaly: Unsupervised detection of sequential and quantitative anomalies in unstructured logs,'' in \textit{Proc. Int. Joint Conf. Artificial Intelligence}, 2019, pp. 4739-4745, doi: \href{https://doi.org/10.24963/ijcai.2019/658}{10.24963/ijcai.2019/658}.

\bibitem{dang2019aiops} Y. Dang, Q. Lin, and P. Huang, ``AIOps: Real-world challenges and research innovations,'' in \textit{Proc. IEEE/ACM Int. Conf. Software Engineering: Companion}, 2019, pp. 4-5, doi: \href{https://doi.org/10.1109/ICSE-Companion.2019.00023}{10.1109/ICSE-Companion.2019.00023}.

\bibitem{chen2021cloudrangerpipeline} J. Chen \textit{et al.}, ``An empirical investigation of incident triage for online service systems,'' in \textit{Proc. IEEE/ACM Int. Conf. Software Engineering: Software Engineering in Practice}, 2021, pp. 111-120, doi: \href{https://doi.org/10.1109/ICSE-SEIP52600.2021.00020}{10.1109/ICSE-SEIP52600.2021.00020}.

\bibitem{chen2023opseval} J. Chen \textit{et al.}, ``OpsEval: A comprehensive task-oriented benchmark for evaluating large language models in operations,'' \textit{arXiv preprint}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2310.07637}

\bibitem{jiang2023logprompt} Z. Jiang \textit{et al.}, ``LogPrompt: Prompt engineering for log-based anomaly detection,'' \textit{arXiv preprint}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2308.07610}

\bibitem{lewis2020retrieval} P. Lewis \textit{et al.}, ``Retrieval-augmented generation for knowledge-intensive NLP tasks,'' in \textit{Advances in Neural Information Processing Systems}, vol. 33, 2020, pp. 9459-9474. [Online]. Available: \url{https://arxiv.org/abs/2005.11401}

\bibitem{asai2023selfrag} A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, ``Self-RAG: Learning to retrieve, generate, and critique through self-reflection,'' in \textit{Proc. Int. Conf. Learning Representations (ICLR)}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2310.11511}

\bibitem{jiang2023active} Z. Jiang \textit{et al.}, ``Active retrieval augmented generation,'' in \textit{Proc. Conf. Empirical Methods in Natural Language Processing (EMNLP)}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2305.06983}

\bibitem{yu2024evaluation} H. Yu \textit{et al.}, ``Evaluation of retrieval-augmented generation: A survey,'' \textit{arXiv preprint}, 2024. [Online]. Available: \url{https://arxiv.org/abs/2405.07437}

\bibitem{gao2023retrieval} Y. Gao \textit{et al.}, ``Retrieval-augmented generation for large language models: A survey,'' \textit{arXiv preprint}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2312.10997}

\bibitem{ram2023context} O. Ram \textit{et al.}, ``In-context retrieval-augmented language models,'' \textit{Trans. Association for Computational Linguistics}, 2023, doi: \href{https://doi.org/10.1162/tacl_a_00605}{10.1162/tacl\_a\_00605}.

\bibitem{cheng2023lift} X. Cheng \textit{et al.}, ``Lift yourself up: Retrieval-augmented text generation with self memory,'' \textit{arXiv preprint}, 2023. [Online]. Available: \url{https://arxiv.org/abs/2305.02437}

\bibitem{balasubramanian2024cygent} P. Balasubramanian, J. Seby, and P. Kostakos, ``CYGENT: A cybersecurity conversational agent with log summarization powered by GPT-3,'' \textit{arXiv preprint}, 2024. [Online]. Available: \url{https://arxiv.org/abs/2403.17160}

\bibitem{granger1969} C. W. J. Granger, ``Investigating causal relations by econometric models and cross-spectral methods,'' \textit{Econometrica}, vol. 37, no. 3, pp. 424-438, 1969, doi: \href{https://doi.org/10.2307/1912791}{10.2307/1912791}.

\bibitem{schreiber2000} T. Schreiber, ``Measuring information transfer,'' \textit{Physical Review Letters}, vol. 85, no. 2, p. 461, 2000, doi: \href{https://doi.org/10.1103/PhysRevLett.85.461}{10.1103/PhysRevLett.85.461}.

\end{thebibliography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author1.png}}]{Krishnatejaswi Shenthar}
is a passionate and curious Computer Science and Engineering graduate from RV College of Engineering, currently working as an AI and Fullstack Engineer with experience as an SDE Intern at RingCentral India, where he builds high-quality software and innovative tools while focusing on clean code, generative AI, and scalable solutions; he has contributed to open-source projects, published work in deep learning applications, and engages deeply with systems design and community-oriented tech development.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author2.png}}]{Yash Saraogi}
is currently pursuing the B.E. degree in Computer Science and Engineering from R. V. College of Engineering, Bengaluru, India. His research interests include Natural Language Processing, Artificial Intelligence, and Deep Learning. He is currently working on a Samsung PRISM project focused on the design and development of a Workflow Management System, with an emphasis on system architecture, automation, and intelligent data processing. His academic and project experience reflect a strong inclination toward building scalable and intelligent software systems.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author3.png}}]{Yash Gautam}
is currently pursuing the bachelors degree in Computer Science and Engineering (Cyber Security) with the R. V. College of Engineering. His academic focus includes the study of secure systems, data protection, and advanced computational techniques. His research interests span machine learning, artificial intelligence, quantum computing, cryptography, and large language models (LLMs), with additional interests in computer vision and natural language processing, particularly in the context of building secure, scalable, and intelligent systems.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author4.png}}]{Mohana} is currently an Associate Professor with the Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, with more than 18 years of academic experience. He has an impressive academic record, having taught a wide range of undergraduate and postgraduate courses, guided numerous student projects, and published more than 130 research papers in international journals and conferences. His research contributions are reflected in his high citation metrics, including an H-index of 26 on Scopus and 27 on Google Scholar, with his work cited in numerous patents. His highlights include being listed in the Elsevier-Stanford Top 2\% Scientists List in the world in 2025 and 2024, and being the Winner of the Unisys Innovation Program (UIP-16) in 2025. His guidance has been instrumental in helping students succeed in various national-level hackathons and project competitions, securing best paper awards in various national and IEEE-sponsored international conferences. He has been involved in fostering industry-academia collaboration, working with Unisys India Pvt. Ltd., Dell, NVIDIA, Wipro, GE Healthcare, Qualitas Technologies, and SLN Innovate Technologies for impactful academic and research initiatives. His research interests include deep learning, AI, quantum computing, computer vision, and image processing. He is a Distinguished Member of IEEE and holds lifetime memberships in the Advanced Computing and Communications Society (ACCS), ISTE, and IAENG.
\end{IEEEbiography}

\EOD

\end{document}
