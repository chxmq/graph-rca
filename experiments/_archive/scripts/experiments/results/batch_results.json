{
  "batch_results": [
    {
      "batch_size": 1,
      "throughput": 1.897,
      "latency_ms": 527.3,
      "std_dev": 0.687,
      "speedup": 1.0,
      "runs": [
        66.67256784439087,
        68.08564162254333,
        66.86821866035461,
        68.15825486183167,
        67.6680428981781
      ]
    },
    {
      "batch_size": 8,
      "throughput": 2.66,
      "latency_ms": 376.0,
      "std_dev": 5.286,
      "speedup": 1.4,
      "runs": [
        52.02757692337036,
        48.08583879470825,
        41.432748317718506,
        54.43303847312927,
        44.66643667221069
      ]
    },
    {
      "batch_size": 16,
      "throughput": 4.666,
      "latency_ms": 214.3,
      "std_dev": 11.852,
      "speedup": 2.46,
      "runs": [
        36.14824175834656,
        29.425248861312866,
        15.64256477355957,
        41.056158781051636,
        14.889476299285889
      ]
    },
    {
      "batch_size": 32,
      "throughput": 12.181,
      "latency_ms": 82.1,
      "std_dev": 11.195,
      "speedup": 6.42,
      "runs": [
        1.9168660640716553,
        19.39574384689331,
        25.531715631484985,
        1.2019894123077393,
        4.492552757263184
      ]
    }
  ],
  "latex": "% Batch Inference Results - 2026-02-01T06:00:16.664379\n\\begin{table}[t]\n\\centering\n\\caption{Batch Inference Performance (Llama 3.2 3B, GPU)}\n\\label{tab:batching}\n\\begin{tabular}{lcccc}\n\\toprule\n\\textbf{Batch Size} & \\textbf{Throughput} & \\textbf{Latency} & \\textbf{Std Dev} & \\textbf{Speedup} \\\\\n\\midrule\n1 (baseline) & 1.90 logs/s & 527 ms & $\\pm$0.7s & 1.0$\\times$ \\\\\n8 & 2.66 logs/s & 376 ms & $\\pm$5.3s & 1.4$\\times$ \\\\\n16 & 4.67 logs/s & 214 ms & $\\pm$11.9s & 2.5$\\times$ \\\\\n32 & 12.18 logs/s & 82 ms & $\\pm$11.2s & 6.4$\\times$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n"
}